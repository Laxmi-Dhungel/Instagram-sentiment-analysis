#Data cleaning and validation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv("instagram.csv")
print(df.dtypes)
print(df["country"].unique()) #unique values: ['DE' 'GB' 'IN' 'CA' 'US']
print(df["date"].unique())  #Has both date and time for each record. may need to do something with date and time.
#Will have additional columns with division based on days and time
print(df["date"].min())
print(df["date"].max())

print(df["score"].unique()) #unique values: [1 4 3 2 5]

print(df["version"].unique()) # unique values: ['323.0.0' '322.1.0' '313.0.0' '322.0.0']

##Duplicates
print(df[df.duplicated()])  #No duplicates


#Check for missing values
print(df.isna().sum())

#Other forms of missing values
null_list=["NAN", "na", "n/a", "-", "--", "nan"]

for cols in df:
    print(cols + ": ", df[df[cols].isin(null_list)])

##No other forms of missing values

#Change country and version to category datatype
df["country"]=df["country"].astype("category")
df["version"]=df["version"].astype("category")

#Create separate columns days and time based on date column
df["date"]=pd.to_datetime(df['date'])  #changing column date to datetime data type

df['day_of_week'] = df['date'].dt.day_name() #Extracting weekdays information and converting to week day to form a new column day_of_week
#df.head()

df['day_of_week']=df['day_of_week'].astype("category")

df["hour"]=df['date'].dt.hour ##Extracting hours from date and creating a new column hour

def hour_conversion(hour):
    if hour >= 0 and hour < 6:
        return 'Mid night-Early morning'
    elif hour>=6 and hour<12:
        return 'Morning'
    elif hour >= 12 and hour < 18:
        return 'Afternoon'
    elif hour >= 18 and hour <= 23:
        return 'Night'
    
df['day_part'] = df['hour'].apply(hour_conversion)   
df['day_part']=df['day_part'].astype("category") 
print(df.dtypes)

############################################
#Sentiment analysis
#import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
#Function for preprocessing text is generated
def preprocess_text(text):
    tokens=word_tokenize(text.lower())
    filtered_tokens=[token for token in tokens if token not in stopwords.words('english')]
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]
    processed_text = ' '.join(lemmatized_tokens) # Join the tokens back into a string
    return processed_text
# apply the function to df
df['text'] = df['text'].apply(preprocess_text)
# initialize NLTK sentiment analyzer
analyzer = SentimentIntensityAnalyzer()
#Create scores_text function
def scores_text(text):
    scores_text=analyzer.polarity_scores(text)
    return scores_text

def get_sentiment(text):# create get_sentiment function 
    scores = analyzer.polarity_scores(text)
    if scores['compound']>0:
        sentiment="positive"
    elif scores['compound']==0:
        sentiment="neutral"
    else:
        sentiment="negative"
    return sentiment
        
def sentiment_value(text): #Function to store scores for compound sentiment
    scores = analyzer.polarity_scores(text)
    sentiment_value=scores['compound']
    return sentiment_value
# apply scores_text and get_sentiment function
df["scores"]=df['text'].apply(scores_text)
df['sentiment'] = df['text'].apply(get_sentiment)
df["sentiment_score"]=df["text"].apply(sentiment_value)

##Review based on country
#Country based review analysis
#Average review for each country
df_country_review=df.groupby("country")["score"].mean()
print(df_country_review)

#Statistical analysis to check significantly difference in average scores given by each country
from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey_country_review=pairwise_tukeyhsd(endog=df["score"], groups=df["country"], alpha=0.05)
tukey_summary_country_review=tukey_country_review.summary()
tukey_df_country_review = pd.DataFrame(data=tukey_summary_country_review.data[1:], columns=tukey_summary_country_review.data[0])
significant_tukey_country_review=tukey_df_country_review[tukey_df_country_review["p-adj"]<=0.05]


#Bar chart for review based on country
bar_country_review=sns.barplot(x="country", y="score", data=df, errorbar="se", capsize=0.5, hue="country")
plt.xlabel("Country")
plt.ylabel("Review score (Rating)")
plt.title("Average review score (Rating) given by each country")
plt.ylim(0,5)
bar_country_review.annotate(" ", xy=(2, 3.2),  xytext=(2, 3.2), arrowprops=dict(color='black', lw=2, arrowstyle='-[', ), ha='center', size=70)
plt.text(2, 3.6, "*", ha='center', fontsize=20)
bar_country_review.annotate(" ", xy=(2.5, 4.0),  xytext=(2.5, 4.0), arrowprops=dict(color='black', lw=2, arrowstyle='-[', ), ha='center', size=95)
plt.text(2.5, 4.6, "*", ha='center', fontsize=20)
plt.show()



#Count of each review country wise
count_review_country_grouped=pd.DataFrame(df.groupby(["country", "score"])["id"].count())
print(count_review_country_grouped)

count_review_country=sns.countplot(x="country", data=df, hue="score")
plt.xlabel("Country")
plt.ylabel("Count")
plt.title("Count of review scores for each country")
sns.move_legend(count_review_country, "upper left", bbox_to_anchor=(1, 1.05))
plt.show()

############################
#Sentiments based on country
#Average sentiment scores and statistical analysis
mean_sentiment_country=df.groupby("country")["sentiment_score"].mean()
print(mean_sentiment_country)

from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey_country_sentiment=pairwise_tukeyhsd(endog=df["sentiment_score"], groups=df["country"], alpha=0.05)
tukey_summary_country_sentiment=tukey_country_sentiment.summary()
tukey_df_country_sentiment = pd.DataFrame(data=tukey_summary_country_sentiment.data[1:], columns=tukey_summary_country_sentiment.data[0])
significant_tukey_country_sentiment=tukey_df_country_sentiment[tukey_df_country_sentiment["p-adj"]<=0.05]
##DE significantly different than all the others

##Average sentiment in each country
sentiment_bar=sns.barplot(x="country", y="sentiment_score", data=df, errorbar="se", capsize=0.5, hue="country")
plt.xlabel("Country")
plt.ylabel("Sentiment score")
plt.title("Average sentiment scores in each country")
plt.text(1.0, 0.01, "*", ha='center', fontsize=20)

plt.show()


#Countplot sentiments
##Sentiment analysis based on country
country_sentiment=sns.catplot(x="country", hue="sentiment", data=df, kind="count")
plt.xlabel("Country")
plt.ylabel("Count")
plt.title("Sentiments towards instagram in each country")

plt.show()

sentiment_country=df.groupby(["country", "sentiment"]).count()
print(sentiment_country)

##############################
#Countplot based on version
df_version_review=df.groupby(["country", "version"])["score"].agg(["mean", "count"])
print(df_version_review)

count_country_version=sns.countplot(x="country", hue="version", data=df)
plt.xlabel("Country")
plt.ylabel("Count")
plt.title("Count of instagram version used in each country")
sns.move_legend(count_country_version, "upper left", bbox_to_anchor=(1, 1.05))

plt.show()

################
#Relationship between sentiments and review scores (Rating)
corr_review_sentiment=df['score'].corr(df['sentiment_score'])
print(corr_review_sentiment)  ##Correlation is 0.36


review_sentiment_mean=df.groupby("score")["sentiment_score"].mean()
print(review_sentiment_mean)

tukey_review_sentiment=pairwise_tukeyhsd(endog=df["sentiment_score"], groups=df["score"], alpha=0.05)
tukey_review_sentiment_summary=tukey_review_sentiment.summary()
tukey_df_review_sentiment=pd.DataFrame(tukey_review_sentiment_summary.data[1:], columns=tukey_review_sentiment_summary.data[0])
significant_tukey_review_sentiment=tukey_df_review_sentiment[tukey_df_review_sentiment["p-adj"]<=0.05]


review_sentiment_bar=sns.barplot(x="score", y="sentiment_score", data=df, errorbar="se", capsize=0.5, hue="score")
plt.xlabel("Review score")
plt.ylabel("Sentiment score")
plt.title("Average sentiment score for each review score")
sns.move_legend(review_sentiment_bar, "upper left", bbox_to_anchor=(1, 1.05))
plt.text(0.08, 0.02, "[4,5]", ha='center', fontsize=15)
plt.text(0.08, 0.04, "*", ha='center', fontsize=20)

plt.text(1, 0.04, "[5]", ha='center', fontsize=15)
plt.text(1, 0.07, "*", ha='center', fontsize=20)

plt.text(2, 0.15, "[5]", ha='center', fontsize=15)
plt.text(2, 0.18, "*", ha='center', fontsize=20)

plt.show()

#Relative percentages
df_review_sentiment=pd.crosstab(df["score"], df["sentiment"])
df_review_sentiment_proportion=pd.crosstab(df["score"], df["sentiment"], normalize="index")
df_review_sentiment_percentages=df_review_sentiment_proportion*100

print(df_review_sentiment_percentages.idxmax(axis=1))
print(df_review_sentiment_percentages.idxmax(axis=0))
print(df_review_sentiment_percentages.idxmin(axis=0))

import pingouin as pg
expected, observed, stats = pg.chi2_independence(df, x='score',  y='sentiment')
print(stats.round(3))

stacked_review_sentiment=df_review_sentiment_percentages.plot(kind="bar", stacked="True")
plt.xlabel("Review score")
plt.ylabel("Relative percentages")
plt.title("Relative percentages of sentiments for each review score")
sns.move_legend(stacked_review_sentiment, "upper left", bbox_to_anchor=(1, 1.05))


plt.show()

#################################

from scipy.stats import chi2_contingency
from itertools import combinations
df_review_sentiment.index=df_review_sentiment.index.astype("category")
ratings_combinations = list(combinations(df_review_sentiment.index, 2))
print(ratings_combinations)
p_ratings=[]

for pairs in ratings_combinations:
    ratings_combinations_data=df_review_sentiment[(df_review_sentiment.index == pairs[0]) | (df_review_sentiment.index == pairs[1])]
    #print(ratings_combinations_data)
    chi2, p, dof, ex = chi2_contingency(ratings_combinations_data, correction=True)
    p_ratings.append(p)
    
#print(p_ratings)
##Correct the p-value list
from statsmodels.sandbox.stats.multicomp import multipletests

reject_list, corrected_p_vals = multipletests(p_ratings, method='fdr_bh')[:2]

for p_val, corr_p_val, reject, pairs in zip(p_ratings, corrected_p_vals, reject_list, ratings_combinations):
    print(pairs, reject )
    
